{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 04 - Normalização de Indicadores\n\nEste notebook realiza:\n1. Filtro de indicadores ativos (CONSIDERAR? = SIM)\n2. Normalização de valores (0-100) **por grupo de posição + competição**\n3. Tratamento de direção (CIMA vs BAIXO)\n\n**Importante**: A normalização é feita separadamente para cada combinação de `mapped_position + competition_id`.\nExemplo: Goleiros (GK) da Serie A são normalizados apenas entre si, não se misturam com GKs de outras ligas nem com outras posições."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"c:/jobs/botafogo/v3\")\n",
    "OUTPUT_DIR = BASE_DIR / \"bases\" / \"outputs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados consolidados\n",
    "df = pd.read_parquet(OUTPUT_DIR / \"_temp_scouts_consolidated.parquet\")\n",
    "print(f\"Jogadores carregados: {len(df)}\")\n",
    "\n",
    "# Carregar pesos ativos\n",
    "df_weights = pd.read_parquet(OUTPUT_DIR / \"_temp_weights_active.parquet\")\n",
    "print(f\"Indicadores ativos: {len(df_weights)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar estrutura dos pesos\n",
    "print(\"Colunas da tabela de pesos:\")\n",
    "print(df_weights.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar indicadores\n",
    "print(f\"\\nIndicadores únicos: {df_weights['INDICADOR'].nunique()}\")\n",
    "print(f\"\\nDireção (Melhor para):\")\n",
    "print(df_weights[\"Melhor para\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Identificar Indicadores Válidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de indicadores que devem ser normalizados\n",
    "indicadores = df_weights[\"INDICADOR\"].str.strip().tolist()\n",
    "\n",
    "# Verificar quais existem no DataFrame de scouts\n",
    "indicadores_disponiveis = [ind for ind in indicadores if ind in df.columns]\n",
    "indicadores_faltantes = [ind for ind in indicadores if ind not in df.columns]\n",
    "\n",
    "print(f\"Indicadores na tabela de pesos: {len(indicadores)}\")\n",
    "print(f\"Indicadores disponíveis nos scouts: {len(indicadores_disponiveis)}\")\n",
    "print(f\"Indicadores faltantes: {len(indicadores_faltantes)}\")\n",
    "\n",
    "if indicadores_faltantes:\n",
    "    print(f\"\\nPrimeiros 10 indicadores faltantes:\")\n",
    "    for ind in indicadores_faltantes[:10]:\n",
    "        print(f\"  - {ind}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar mapeamento de direção para cada indicador\n",
    "direction_map = dict(zip(\n",
    "    df_weights[\"INDICADOR\"].str.strip(),\n",
    "    df_weights[\"Melhor para\"]\n",
    "))\n",
    "\n",
    "print(f\"Mapeamento de direção criado para {len(direction_map)} indicadores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Função de Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(series, direction=\"CIMA\"):\n",
    "    \"\"\"\n",
    "    Normaliza uma série de valores para o intervalo 0-100.\n",
    "    \n",
    "    Args:\n",
    "        series: pd.Series com os valores a normalizar\n",
    "        direction: 'CIMA' (maior é melhor) ou 'BAIXO' (menor é melhor)\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series normalizada (0-100)\n",
    "    \"\"\"\n",
    "    # Ignorar NaN para cálculos\n",
    "    min_val = series.min()\n",
    "    max_val = series.max()\n",
    "    \n",
    "    # Evitar divisão por zero\n",
    "    if max_val == min_val:\n",
    "        return pd.Series([50.0] * len(series), index=series.index)\n",
    "    \n",
    "    # Normalização\n",
    "    if direction == \"CIMA\":\n",
    "        # Maior valor = 100\n",
    "        normalized = (series - min_val) / (max_val - min_val) * 100\n",
    "    else:  # BAIXO\n",
    "        # Menor valor = 100\n",
    "        normalized = (max_val - series) / (max_val - min_val) * 100\n",
    "    \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Aplicar Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Criar DataFrame para valores normalizados\ndf_normalized = df.copy()\n\n# Criar coluna de grupo para normalização: posição + competição\ndf_normalized[\"_norm_group\"] = df_normalized[\"mapped_position\"].astype(str) + \"_\" + df_normalized[\"competition_id\"].astype(str)\n\n# Verificar grupos criados\ngrupos = df_normalized[\"_norm_group\"].nunique()\nprint(f\"Grupos de normalização (posição + competição): {grupos}\")\nprint(f\"\\nExemplos de grupos:\")\nprint(df_normalized[\"_norm_group\"].value_counts().head(10))\n\n# Normalizar cada indicador por grupo\nnormalized_count = 0\nerrors = []\n\nfor indicador in indicadores_disponiveis:\n    try:\n        direction = direction_map.get(indicador, \"CIMA\")\n        \n        # Converter para numérico se necessário\n        df_normalized[indicador] = pd.to_numeric(df_normalized[indicador], errors=\"coerce\")\n        \n        # Normalizar POR GRUPO (posição + competição)\n        df_normalized[f\"{indicador}_norm\"] = df_normalized.groupby(\"_norm_group\")[indicador].transform(\n            lambda x: normalize_column(x, direction)\n        )\n        normalized_count += 1\n        \n    except Exception as e:\n        errors.append((indicador, str(e)))\n\n# Remover coluna auxiliar\ndf_normalized.drop(columns=[\"_norm_group\"], inplace=True)\n\nprint(f\"\\nIndicadores normalizados: {normalized_count}\")\nif errors:\n    print(f\"\\nErros ({len(errors)}):\")\n    for ind, err in errors[:5]:\n        print(f\"  - {ind}: {err}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar normalização\n",
    "norm_cols = [c for c in df_normalized.columns if c.endswith(\"_norm\")]\n",
    "print(f\"\\nColunas normalizadas criadas: {len(norm_cols)}\")\n",
    "\n",
    "# Estatísticas de uma coluna normalizada\n",
    "if norm_cols:\n",
    "    sample_col = norm_cols[0]\n",
    "    print(f\"\\nEstatísticas de '{sample_col}':\")\n",
    "    print(df_normalized[sample_col].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verificar Valores Normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se todos os valores estão no range 0-100\n",
    "out_of_range = 0\n",
    "for col in norm_cols:\n",
    "    values = df_normalized[col].dropna()\n",
    "    if (values < 0).any() or (values > 100).any():\n",
    "        out_of_range += 1\n",
    "        print(f\"  {col}: min={values.min():.2f}, max={values.max():.2f}\")\n",
    "\n",
    "if out_of_range == 0:\n",
    "    print(\"Todos os valores normalizados estão no range 0-100!\")\n",
    "else:\n",
    "    print(f\"\\n{out_of_range} colunas com valores fora do range\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de normalização (antes e depois)\n",
    "if indicadores_disponiveis:\n",
    "    sample_ind = indicadores_disponiveis[0]\n",
    "    print(f\"\\nExemplo: {sample_ind}\")\n",
    "    print(f\"Direção: {direction_map.get(sample_ind, 'CIMA')}\")\n",
    "    print(f\"\\nAntes (original):\")\n",
    "    print(df_normalized[sample_ind].describe())\n",
    "    print(f\"\\nDepois (normalizado):\")\n",
    "    print(df_normalized[f\"{sample_ind}_norm\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Criar Mapeamento de Indicadores para Pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrame com mapeamento indicador -> peso por posição\n",
    "position_columns = [\"GK\", \"RCB\", \"LCB\", \"CB\", \"RB\", \"LB\", \"DM\", \"CM\", \"AM\", \"LW\", \"RW\", \"CF\"]\n",
    "\n",
    "# Verificar quais colunas de posição existem\n",
    "available_pos_cols = [c for c in position_columns if c in df_weights.columns]\n",
    "print(f\"Colunas de posição disponíveis: {available_pos_cols}\")\n",
    "\n",
    "# Criar mapeamento indicador -> pesos\n",
    "weights_dict = {}\n",
    "for _, row in df_weights.iterrows():\n",
    "    indicador = row[\"INDICADOR\"].strip()\n",
    "    if indicador in indicadores_disponiveis:\n",
    "        weights_dict[indicador] = {}\n",
    "        for pos in available_pos_cols:\n",
    "            weights_dict[indicador][pos] = row[pos] if pd.notna(row[pos]) else 0\n",
    "\n",
    "print(f\"\\nMapeamento de pesos criado para {len(weights_dict)} indicadores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Salvar Dados Normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar DataFrame normalizado\n",
    "df_normalized.to_parquet(OUTPUT_DIR / \"_temp_scouts_normalized.parquet\", index=False)\n",
    "print(f\"Dados normalizados salvos: {OUTPUT_DIR / '_temp_scouts_normalized.parquet'}\")\n",
    "\n",
    "# Salvar mapeamento de pesos como JSON para próxima etapa\n",
    "import json\n",
    "with open(OUTPUT_DIR / \"_temp_weights_map.json\", \"w\") as f:\n",
    "    json.dump(weights_dict, f)\n",
    "print(f\"Mapeamento de pesos salvo: {OUTPUT_DIR / '_temp_weights_map.json'}\")\n",
    "\n",
    "# Salvar lista de indicadores disponíveis\n",
    "with open(OUTPUT_DIR / \"_temp_indicators_available.json\", \"w\") as f:\n",
    "    json.dump(indicadores_disponiveis, f)\n",
    "print(f\"Lista de indicadores salva: {OUTPUT_DIR / '_temp_indicators_available.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo\n",
    "print(\"=\" * 50)\n",
    "print(\"RESUMO DA NORMALIZAÇÃO\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Jogadores: {len(df_normalized)}\")\n",
    "print(f\"Indicadores normalizados: {len(norm_cols)}\")\n",
    "print(f\"Colunas totais: {len(df_normalized.columns)}\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}