{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Exportação Final\n",
    "\n",
    "Este notebook realiza:\n",
    "1. Seleção de colunas finais\n",
    "2. Exportação para parquet:\n",
    "   - consolidated_overral.parquet\n",
    "   - consolidated_weights.parquet\n",
    "   - consolidated_context.parquet\n",
    "   - consolidated_normalized.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"c:/jobs/botafogo/v3\")\n",
    "OUTPUT_DIR = BASE_DIR / \"bases\" / \"outputs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados com scores\n",
    "df = pd.read_parquet(OUTPUT_DIR / \"_temp_scouts_scored.parquet\")\n",
    "print(f\"Dados carregados: {len(df)} jogadores, {len(df.columns)} colunas\")\n",
    "\n",
    "# Carregar pesos\n",
    "df_weights = pd.read_parquet(OUTPUT_DIR / \"_temp_weights_active.parquet\")\n",
    "print(f\"Pesos carregados: {len(df_weights)} indicadores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exportar consolidated_overral.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Colunas principais conforme o plano\nmain_cols = [\n    \"player_id\",\n    \"competition_id\",\n    \"player_name\",\n    \"competition_name\",\n    \"team_name\",\n    \"primary_position\",\n    \"mapped_position\",\n    \"position_group\",\n    \"position_sub_group\",\n    \"v_current\",\n    \"overall_score\",\n    \"rank_overall\",\n    \"rank_position\",\n]\n\n# Adicionar colunas de score por categoria\nscore_cols = [c for c in df.columns if c.startswith(\"score_\")]\nmain_cols.extend(score_cols)\n\n# Filtrar colunas disponíveis\navailable_main_cols = [c for c in main_cols if c in df.columns]\nprint(f\"Colunas para overall: {len(available_main_cols)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrame overall\n",
    "df_overall = df[available_main_cols].copy()\n",
    "\n",
    "# Ordenar por ranking\n",
    "df_overall = df_overall.sort_values(\"rank_overall\")\n",
    "\n",
    "print(f\"DataFrame overall: {len(df_overall)} linhas, {len(df_overall.columns)} colunas\")\n",
    "print(f\"\\nColunas: {df_overall.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar\n",
    "df_overall.to_parquet(OUTPUT_DIR / \"consolidated_overral.parquet\", index=False)\n",
    "print(f\"Exportado: {OUTPUT_DIR / 'consolidated_overral.parquet'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exportar consolidated_weights.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar tabela de pesos utilizada\n",
    "df_weights.to_parquet(OUTPUT_DIR / \"consolidated_weights.parquet\", index=False)\n",
    "print(f\"Exportado: {OUTPUT_DIR / 'consolidated_weights.parquet'}\")\n",
    "print(f\"  {len(df_weights)} indicadores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exportar consolidated_context.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Colunas de contexto/metadados\ncontext_cols = [\n    \"player_id\",\n    \"competition_id\",\n    \"unique_key\",\n    \"source_file\",\n    \"v_current\",\n    \"player_season_most_recent_match\",\n]\n\n# Adicionar outras colunas de contexto disponíveis\nextra_context = [c for c in df.columns if any([\n    \"player_\" in c.lower(),\n    \"team_\" in c.lower(),\n    \"competition_\" in c.lower(),\n    \"season\" in c.lower(),\n]) and not c.endswith(\"_norm\") and c not in main_cols]\n\ncontext_cols.extend(extra_context)\navailable_context_cols = list(set([c for c in context_cols if c in df.columns]))\n\nprint(f\"Colunas de contexto: {len(available_context_cols)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar e exportar DataFrame de contexto\n",
    "df_context = df[available_context_cols].copy()\n",
    "df_context.to_parquet(OUTPUT_DIR / \"consolidated_context.parquet\", index=False)\n",
    "print(f\"Exportado: {OUTPUT_DIR / 'consolidated_context.parquet'}\")\n",
    "print(f\"  {len(df_context)} linhas, {len(df_context.columns)} colunas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exportar consolidated_normalized.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Colunas de identificação + valores normalizados\nid_cols = [\"player_id\", \"competition_id\", \"unique_key\", \"mapped_position\", \"v_current\"]\nnorm_cols = [c for c in df.columns if c.endswith(\"_norm\")]\n\nnormalized_cols = [c for c in id_cols if c in df.columns] + norm_cols\nprint(f\"Colunas normalizadas: {len(norm_cols)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar e exportar DataFrame normalizado\n",
    "df_normalized = df[normalized_cols].copy()\n",
    "df_normalized.to_parquet(OUTPUT_DIR / \"consolidated_normalized.parquet\", index=False)\n",
    "print(f\"Exportado: {OUTPUT_DIR / 'consolidated_normalized.parquet'}\")\n",
    "print(f\"  {len(df_normalized)} linhas, {len(df_normalized.columns)} colunas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Limpar Arquivos Temporários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar arquivos temporários\n",
    "temp_files = list(OUTPUT_DIR.glob(\"_temp_*\"))\n",
    "print(f\"Arquivos temporários: {len(temp_files)}\")\n",
    "for f in temp_files:\n",
    "    print(f\"  {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomente para remover arquivos temporários\n",
    "# for f in temp_files:\n",
    "#     f.unlink()\n",
    "#     print(f\"Removido: {f.name}\")\n",
    "# print(\"\\nArquivos temporários removidos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resumo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar arquivos exportados\n",
    "final_files = [\n",
    "    \"consolidated_overral.parquet\",\n",
    "    \"consolidated_weights.parquet\",\n",
    "    \"consolidated_context.parquet\",\n",
    "    \"consolidated_normalized.parquet\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPORTAÇÃO CONCLUÍDA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for filename in final_files:\n",
    "    filepath = OUTPUT_DIR / filename\n",
    "    if filepath.exists():\n",
    "        size_mb = filepath.stat().st_size / (1024 * 1024)\n",
    "        df_check = pd.read_parquet(filepath)\n",
    "        print(f\"\\n{filename}\")\n",
    "        print(f\"  Tamanho: {size_mb:.2f} MB\")\n",
    "        print(f\"  Linhas: {len(df_check):,}\")\n",
    "        print(f\"  Colunas: {len(df_check.columns)}\")\n",
    "    else:\n",
    "        print(f\"\\n{filename}: NÃO ENCONTRADO\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview do arquivo principal\n",
    "print(\"\\nPreview - Top 10 Overall:\")\n",
    "df_final = pd.read_parquet(OUTPUT_DIR / \"consolidated_overral.parquet\")\n",
    "display_cols = [\"player_name\", \"mapped_position\", \"overall_score\", \"rank_overall\"]\n",
    "df_final.head(10)[display_cols]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}